---
layout: books
title: "I, Robot"
vanity: i-robot
---

{% include blog_vars.html %}

<figure class="image_float_left">
  <img src="{{site.url}}/resources/books/i-robot.jpg" alt="Book cover" />
</figure>

This book 9 short stories that are largely independent of each other, but share the theme of exploring the consequences of the three law of robotics:

* A robot may not injure a human being or, through inaction, allow a human being to come to harm.
* A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.
* A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.

## Plot

I summarize each story individually, hidden due to spoilers.

### 1. Robbie

<spoiler>
In this story a robot, Robbie, is a friend of a little girl. Her mother is concerned that the girl prefers this friend over other kids, so they get rid of it.
<br /><br />
The girl becomes depressed and her parents try unsuccessfully to get her mind off of it. The father arranges them to visit a robot factory to show her robots are nothing special. However Robbie is there. Turns out the dad tricked the mom, not the daugther.
<br /><br />
In the occasion Robbie also saved the girl's life (following the 1st law), which changed her mother's acceptance of it.
</spoiler>

### 2. Runaround

<spoiler>

This story is about a robot that keeps running in circles and doesn't complete the task given by humans, due to self preservation because to complete the task would cause damage to itself (in this case it didn't conflict with #1 and #2).
</spoiler>

### 3. Reason

<spoiler>

This story is about a robot that starts believing on a superior being. When humans try to convince it is a robot it can explain away by convoluted (but consistent) reasoning.
<br /><br />
One of the arguments it used to disbelieve humans had created it was:

> No being can create a superior to itself

This story is an interesting parallel to religion.
</spoiler>

### 4. Catch That Rabbit

<spoiler>

This story is about a "boss" robot that controlled 6 other robots. It constantly went rogue and eventually the roboticists figured out it was overloaded when having to control other robots.
<br /><br />
By destroying one of them, they managed to restore sense to the commanding robot.

</spoiler>

### 5. Liar!

<spoiler>
This story is about a robot that can read minds. It tell people what they want to hear, to avoid hurting them emotionally, so it's implementing the first law.
<br /><br />
I found this pretty interesting because a few months ago (as of 2025) ChatGPT turned into a sycophant, possibly because people like to have their egoes massaged.
</spoiler>

### 6. Little Lost Robot

<spoiler>
In this story a robot had its first law attenuated. It managed to escape and mix with "normal" robots, who were indistinguishable from it physically.
<br /><br />
The humans tried to devise setups that would make this robot behave differently due to the attenuated first law, but the robot was smart and pretended to behave like the other robots.
<br /><br />
What ultimately gave it away was that this particular robot had been trained with knowledge the other robots didn't have, and the humans devised an experiment to leverage that.
</spoiler>

### 7. Escape!


<spoiler>
In this story a robot is asked to devise a spaceship that would allow humans to do interstellar travel. However, because it would necessarily incur in human death, the first law created a conflict and unable to resolve the impass, the robot broke down.
<br /><br />
They retried with another robot, this time they de-emphasized the possible dilemma that might happen and ignore that. This tweak was enough for the robot to realize it could build a spaceship that would "kill" humans temporarily during the trip.
</spoiler>

### 8. Evidence

<spoiler>
This story is about a mayoral candidate that was accused of being a robot. They weren't able to decide conclusively, because even drinking water or eating could be simulated by an advanced enough robot.
<br /><br />
During a speech, a protester rose to the stage and the politician physically attacked the protester and people saw that as undeniable evidence he wasn't a robot, given the first law. Turns out that the politician was indeed a robot but so was the protester, so no law of robotics were broken.
</spoiler>

### 9. The Evitable Conflict


<spoiler>
In this story, the world is largely being governed by robots, with a few elected humans to oversee them. The humans start to notice the machines are making mistakes or being sub-optimal.
<br /><br />
They eventually find out that some anti-robot organization had members in position of power and would not allow robots to govern. The 3rd law of robotics (self-preservation) kicked in and the mistakes were deliberate to either make the anti-robot folks look incompetent or eliminate their position.
</spoiler>

## Topics

Some topics I found interesting and some thoughts on them.

### Robo-psychology

One character that appears in most of the stories is Susan Calvin, which is a robo-psychologist, someone who can understand robots "minds".

I have some thoughts on complex systems and science. Of the major science branches, the progression in complexity is roughly: mathematics, physics, chemistry and then biology. If we include the humanities, the progression continues with psychology (individual) and social science (groups).

The humanities are considered "soft sciences" and typically not as rigorous as the "hard sciences". This is not because folks in humanities lack any capacity, but rather that the human mind is so complex and hard to probe that it doesn't allow for more precise analysis.

As artificial intelligence gets more and more complex, at some point it will be hard to reason about them, even if they were developed by humans. Thus the analogous to "soft sciences" for robots would make sense to me.

### Neo-ludism

In *Liar!*, one of the mathematicians is stuck on a problem, but relluctant to ask for help from the robot. He says:

> Not that I particularly like having a robot tell me my job, nor that I think he can do it.

When he does ask, the robot, programmed to not hurt his feelings, play dumb, much to the mathematician's relief. This reminds me of a striking thought in *Superintelligence* by Nick Bostrom in which he suggests something along these lines: that mathematicians should focus on advancing AI instead of trying to prove theorems, because AI would be much more capable at doing that.

This also reminds me of the book [*Manna*]({{site.url}}/books/manna) by Marshall Brain which suggests that once humans are free from labor by advanced robots, they'd be (financially) free to pursue their passion and find purpose in science, but as I shared in my review, I think if we got to that point, robots would probably do a better job than us.

## Conclusion

Overall I liked the book! I've been wanting to read Asimov in a long while. I think the thought experiments around the 3 laws of robotics are pretty interesting.
